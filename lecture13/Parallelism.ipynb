{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parallelism**\n",
    "\n",
    "Your laptop probably has multiple cores (4 is a typical number). Practically speaking, this means you have the capability of running processes in parallel, i.e. simultaneously. This is especially helpful when the task at hand is trivially parallelizable. \n",
    "\n",
    "The kinds of Monte-Carlo simulations we've been doing are great examples. Instead of generating realizations and checking some condition in series we can hand the task off to each processor. Thus, putting aside the overhead associated with making this all work, if we have 4 cores we can do our processing 4 times as fast.\n",
    "\n",
    "We illustrate with the following question. For a sequence of n Bernoulli trials with success probability p, how many times do we expect to have a 1 followed by a 0 or a 0 followed by a 1?\n",
    "\n",
    "First consider the non-parallelized version of the code. The code has been written in such a way as to be easily modified when we code the parallel version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Non parallel version of Monte-Carlo program.\n",
    "# Question - Flip a coin P(heads)=p P(tails)=1-p n times. \n",
    "# What is the expected number of times we see a change from 0 to 1 or 1 to 0\n",
    "# We do N Monte-Carlo trials.\n",
    "#\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "#\n",
    "# Function to return the number of changes from 0 to 1 or 1 to 0\n",
    "# in a list of 0's and 1's\n",
    "#\n",
    "def number_of_changes(X):\n",
    "    s=X[0] # value in current run\n",
    "    nchanges=0\n",
    "    for i in range(1,n):\n",
    "        if X[i]==s: # no change\n",
    "            continue\n",
    "        else:\n",
    "            s=X[i]\n",
    "            nchanges+=1\n",
    "    return(nchanges)\n",
    "\n",
    "#\n",
    "# Function to do a single realization of n Bernoulli(p) trials \n",
    "# and call the number of changes program. The function takes a tuple \n",
    "# of arguments (n,p).\n",
    "#\n",
    "def simulate_once(args):\n",
    "    n=args[0]\n",
    "    p=args[1]\n",
    "    X=np.random.choice([0,1],size=n,p=[p,1-p])\n",
    "    LR=number_of_changes(X)\n",
    "    return(LR)\n",
    "#\n",
    "# Set the values of the parameters\n",
    "#\n",
    "N=10000\n",
    "n=1000\n",
    "p=.75\n",
    "#\n",
    "# Create a list of 2-tuples and apply simulate_once() to every 2-tuple using\n",
    "# map.\n",
    "#\n",
    "time0 = time.process_time()\n",
    "arglist=[(n,p) for i in range(N)]\n",
    "result = list(map(simulate_once,arglist))\n",
    "time1=time.process_time()\n",
    "print(\"time = \"+ \"{:10.3f}\".format(time1-time0))\n",
    "print(\"mean = \" + \"{:10.3f}\".format(np.mean(np.array(result))))\n",
    "print(\"std err = \" + \"{:10.3f}\".format(np.std(np.array(result))/np.sqrt(N)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parallel version**\n",
    "\n",
    "Here is the parallel version of the progrm (which doesn't work in jupyter notebooks). To run this program, copy it to a file - e.g. program2.py in some folder e in your file system, then in a terminal (or anaconda prompt) navigate to that folder and at the prompt (shown here as >), (assuming python is in your path) type:\n",
    "\n",
    "$>$ python program.py\n",
    "\n",
    "Alternatively, you can use the spyder IDE or some other environment to run the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "#\n",
    "# Function to return the number of changes from 0 to 1 or 1 to 0\n",
    "# in a list of 0's and 1's\n",
    "#\n",
    "def number_of_changes(X):\n",
    "    s=X[0] # value in current run\n",
    "    nchanges=0\n",
    "    for i in range(1,n):\n",
    "        if X[i]==s: # no change\n",
    "            continue\n",
    "        else:\n",
    "            s=X[i]\n",
    "            nchanges+=1\n",
    "    return(nchanges)\n",
    "\n",
    "\n",
    "def simulate_once(args):\n",
    "    n=args[0]\n",
    "    p=args[1]\n",
    "    X=np.random.choice([0,1],size=n,p=[p,1-p])\n",
    "    LR=number_of_changes(X)\n",
    "    return(LR)\n",
    "\n",
    "N=1000\n",
    "n=1000\n",
    "p=.75\n",
    "nprocesses=4\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    time0 = time.time()\n",
    "    #\n",
    "    # create a pool of workers\n",
    "    #\n",
    "    pool = mp.Pool(nprocesses)\n",
    "    #\n",
    "    # create a list of arguments\n",
    "    #\n",
    "    arglist=[(n,p) for i in range(N)]\n",
    "    #\n",
    "    # use pool.map to apply the simulate_once function to every\n",
    "    # element in the argument list\n",
    "    #\n",
    "    result = pool.map(simulate_once,arglist)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    time1=time.time()\n",
    "    print(\"time = \"+ \"{:10.3f}\".format(time1-time0))\n",
    "    print(\"mean = \" + \"{:10.3f}\".format(np.mean(np.array(result))))\n",
    "    print(\"std err = \" + \"{:10.3f}\".format(np.std(np.array(result))/np.sqrt(N)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is from stackoverflow: https://stackoverflow.com/questions/20360686/compulsory-usage-of-if-name-main-in-windows-while-using-multiprocessi\n",
    "\n",
    "The multiprocessing module works by creating new Python processes that will import your module. If you did not add __name__== '__main__' protection then you would enter a never ending loop of new process creation. It goes like this:\n",
    "\n",
    "- Your module is imported and executes code during the import that cause multiprocessing to spawn 4 new processes.\n",
    "\n",
    "- Those 4 new processes in turn import the module and executes code during the import that cause multiprocessing to spawn 16 new processes.\n",
    "\n",
    "- Those 16 new processes in turn import the module and executes code during the import that cause multiprocessing to spawn 64 new processes.\n",
    "\n",
    "Well, hopefully you get the picture.\n",
    "\n",
    "So the idea is that you make sure that the process spawning only happens once. And that is achieved most easily with the idiom of the __name__== '__main__' protection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
